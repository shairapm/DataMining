---
title: "Tarea_Mineria"
author: "Shaira Pérez"
output: html_document
---

  El objetivo de este informe es clasificar qué tan aceptable es cierto carro estableciendo una relación entre su precio total y sus comodidades, entre ellas la seguridad que ofrece.

  Para esto utilizamos un modelo obtenido de evaluar las instancias del [repositorio](http://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data) de un DataSet. El cual contiene las siguientes variables:

  Variable  |   Tipo    |   D.A   |        Rango          |           Explicación                     |
----------- |:---------:|:-------:|:---------------------:|:-------------------------------------:    |
buying      | Ordinal   |   No    |v-high, high, med, low | El precio total de compra                 |
maint       | Ordinal   |   No    |v-high, high, med, low | Precio de mantenimiento                   |
doors       | Ordinal   |   No    |    2, 3, 4, 5-more    | Número de puertas                         |
persons     | Ordinal   |   No    |     2, 4, more        | Capacidad de personas que pueden ocuparlo |
lug_boot    | Ordinal   |   No    |  small, med, big      | Tamaño de la maleta                       |
safety      | Ordinal   |   No    | low, med, high        | Seguridad estimada                        |
class       | Ordinal   |   No    |unacc, acc, good, vgood| Aceptabilidad del carro en cuestión       |

##Obtención de los datos

  Procedemos a descargar el dataset car.data, el cual contiene las instancias del modelo descrito anteriormente. Son 1728 instancias, las cuales tienen un valor en todos los atributos, es decir, el dataset no tiene valores NA.

```{r, echo=FALSE, cache=TRUE}
#2._ Obtener Dataset car
data<- read.csv(url("http://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data"), header = FALSE, col.names=c("buying","maint", "doors", "persons", "lug_boot", "safety","class"))
data
```

##Preprocesamiento de los datos

  Antes de realizar el análisis, se instalan los paquetes necesarios para realizar todas las operaciones. 

```{r, echo=FALSE}
#1._ Importar librerías necesarias para .Rmd
install = function(pkg){
  #Si ya está instalado, no lo instala.
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    if (!require(pkg, character.only = TRUE)) stop(paste("load failure:", pkg))
  }
}

install("foreach")

archive = c("rJava", "shiny", "rpart.plot", "rmarkdown", "foreach", "caret", "e1071", "rpart", "tree", "RWeka", "C50")
foreach(i = archive) %do% install(i)

```
  
  Ahora se realiza una selección de variables para obtener una representación reducida del conjunto de datos, que es mucho más pequeña en volumen pero produce los mismos (o casi iguales) resultados analíticos.
  
```{r echo=TRUE}
#3._ Selección de variables
data$buying <- as.factor(data$buying)
data$maint <- as.factor(data$maint)
data$doors <- as.factor(data$doors)
data$persons <- as.factor(data$persons)
data$lug_boot <- as.factor(data$lug_boot)
data$safety <- as.factor(data$safety)

DT<-as.data.frame(data)

AttributeSelection <- make_Weka_filter("weka.filters.supervised.attribute.AttributeSelection")

rd=AttributeSelection(class ~ ., DT, control = Weka_control(E = "weka.attributeSelection.InfoGainAttributeEval", S = "weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N 4"))
```

##División de los datos

 Con el set de datos resultante del preprocesamiento se realiza un muestreo aleatorio con 80% de los datos para entrenamiento y 20% para prueba.

```{r echo=2:3}
#4._ Particionamiento de la data en 80% entrenamiento y 20% prueba usando muestreo aleatorio
trainIndex = createDataPartition(y=rd$class, p= 0.8, list=FALSE, times=1)
dataTrain <- rd[trainIndex,]
dataTest <- rd[-trainIndex,]
```

  Otra técnica para realizar la división del dataset es validación cruzada:
  
```{r echo=TRUE}
#BONO: Particionamiento de la data usando validación cruzada
cruzada = createFolds(y = rd$class, k = 2, list = TRUE, returnTrain = FALSE)

```

##Generación del Modelo

  La clasificación se realizará con el modelo de árbol de decisión. Y para esto primero se aplica el algoritmo C4.5 (provisto por la librería RWeka), el cual construye el árbol desde el conjunto de datos de entrenamiento, el cual es un ejemplo ya clasificado.  

```{r echo=FALSE}
#5._Generación del modelo
AD <- J48(class ~., rd, control=Weka_control(C = 0.25, M=40)) #AD=árbol de decisión
plot(AD)
```

  Sin embargo, otra manera de generar el árbol de decisión es a través del paquete Rpart, dando como resultado:

## Modelo Rpart

```{r echo=FALSE}
fit1 <- rpart(class ~ .,rd, control=rpart.control(minsplit=2,cp=0.01), method="class")
fit2 <- rpart(class ~ .,rd, control=rpart.control(minsplit=140,cp=0.1), method="class")
fit3 <- rpart(class ~ .,rd, control=rpart.control(minsplit=550,cp=0.01), method="class")
fit4 <- rpart(class ~ .,rd, control=rpart.control(minsplit=1152,cp=0.01), method="class")

rpart.plot(fit1)

```

##Predicción y Matriz de Confusión

  En un sentido estricto ninguna clasificación puede considerarse completa hasta que su grado de exactitud sea evaluado. Este puede definirse como el grado de concordancia entre las clases asignadas por el clasificador y sus ubicaciones correctas. 
  
  El instrumento más usual para evaluar la exactitud de una clasificación es la matriz de  confusión, la cual permite observar fácilmente si el sistema esta confundiendo las clases.
  
  La matriz de confusión asociada al modelo generado por el algoritmo C4.5:

```{r echo=FALSE}
test <- dataTest 
test$class=NULL
confusionMatrix(predict(AD,test,type="class"), dataTest$class)
```

  Y la asociada a Rpart:

```{r echo=FALSE}
c1 = confusionMatrix(predict(fit1,test,type="class"), dataTest$class)
c2 = confusionMatrix(predict(fit2,test,type="class"), dataTest$class)
c3 = confusionMatrix(predict(fit3,test,type="class"), dataTest$class)
c4 = confusionMatrix(predict(fit4,test,type="class"), dataTest$class)
```


Escenario |     Accuracy    |
--------- |:---------------:|
1         |`r c1$overall[1]`|
2         |`r c2$overall[1]`|
3         |`r c3$overall[1]`|
4         |`r c4$overall[1]`|


